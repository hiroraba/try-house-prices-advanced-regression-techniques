{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## IMPORT LIBRARY"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/matsuohiroki/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:320068)",
      "at w.execute (/Users/matsuohiroki/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:319389)",
      "at w.start (/Users/matsuohiroki/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:315205)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/matsuohiroki/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (/Users/matsuohiroki/.vscode/extensions/ms-toolsai.jupyter-2021.8.1054968649/out/client/extension.js:90:329272)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CONSTRAINT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DEBUG = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if platform.system() == 'Darwin':\n",
    "    PATH = './'\n",
    "else:\n",
    "    PATH = '/content/drive/MyDrive/Colab Notebooks/Kaggle/House-Prices/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SET SEED"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.random.seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## READ DATA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train = pd.read_csv(f'{PATH}train.csv')\n",
    "df_test = pd.read_csv(f'{PATH}test.csv')\n",
    "\n",
    "# テストIDを別途保存しておく\n",
    "test_ID = df_test['Id']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## REMOVE OUTER VALUE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.drop(\"Id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "df_train[\"TotalSF\"] = df_train[\"1stFlrSF\"] + df_train[\"2ndFlrSF\"] + df_train[\"TotalBsmtSF\"]\n",
    "df_test[\"TotalSF\"] = df_test[\"1stFlrSF\"] + df_test[\"2ndFlrSF\"] + df_test[\"TotalBsmtSF\"]\n",
    "\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAKE DATA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# データを合体\n",
    "df = pd.concat([df_train, df_test], sort=False)\n",
    "\n",
    "df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\n",
    "df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"None\")\n",
    "df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")\n",
    "df[\"Fence\"] = df[\"Fence\"].fillna(\"None\")\n",
    "df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")\n",
    "df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 'RL'が一番多いのでそれで埋める\n",
    "df['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n",
    "\n",
    "df[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")\n",
    "\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    df[col] = df[col].fillna('None')\n",
    "    \n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    df[col] = df[col].fillna(0)\n",
    "    \n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    df[col] = df[col].fillna(0)\n",
    "    \n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    df[col] = df[col].fillna('None')\n",
    "\n",
    "df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\n",
    "df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0)\n",
    "\n",
    "# 電気がないことはないので最頻値で埋める\n",
    "df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "\n",
    "df = df.drop(['Utilities'], axis=1)\n",
    "\n",
    "# キッチンがないことはないので最頻値で埋める\n",
    "df['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n",
    "\n",
    "df['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\n",
    "df['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n",
    "\n",
    "df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n",
    "df['MSSubClass'] = df['MSSubClass'].fillna(\"None\")\n",
    "\n",
    "## カテゴリにしたい数値型の特徴量を文字列に変換\n",
    "#MSSubClass=The building class\n",
    "df['MSSubClass'] = df['MSSubClass'].apply(str)\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "df['OverallCond'] = df['OverallCond'].astype(str)\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "df['YrSold'] = df['YrSold'].astype(str)\n",
    "df['MoSold'] = df['MoSold'].astype(str)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(df[c].values)) \n",
    "    df[c] = lbl.transform(list(df[c].values))\n",
    "    \n",
    "df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "\n",
    "# 正規化    \n",
    "numeric_features = df.dtypes[df.dtypes != \"object\"].index\n",
    "# 歪みを数値化\n",
    "skewed_features = df[numeric_features].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "high_skewness = skewed_features[abs(skewed_features) > 0.9]\n",
    "skewed_features = high_skewness.index\n",
    "\n",
    "# 0.9以上のものを補正をかける\n",
    "for feature in skewed_features:\n",
    "    if feature != 'SalePrice': \n",
    "        df[feature] = boxcox1p(df[feature], 0.15)\n",
    "\n",
    "# one-hot-Encoding\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# 訓練データを作成\n",
    "y = np.log1p(df[:df_train.shape[0]]['SalePrice'])\n",
    "X = df[:df_train.shape[0]].drop(['SalePrice'], axis=1)\n",
    "\n",
    "# 検証\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RSME"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rmse(y_true,y_pred):\n",
    "    #RMSEを算出\n",
    "    rmse = np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "    return rmse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAKE MODEL AND FIT (XGBOOST)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import copy\n",
    "base_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "}\n",
    "\n",
    "tmp_params = copy.deepcopy(base_params)\n",
    "\n",
    "watchlist = [(trains, 'train'), (tests, 'eval')]\n",
    "\n",
    "def optimizer(trial):\n",
    "#     booster = trial.suggest_categorical('booster', ['gbtree', 'dart', 'gblinear'])\n",
    "    eta = trial.suggest_uniform('eta', 0.01, 0.3)\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 15)\n",
    "    __lambda = trial.suggest_uniform('lambda', 0.7, 2)\n",
    "\n",
    "#     params['booster'] = booster\n",
    "    tmp_params['eta'] = eta\n",
    "    tmp_params['max_depth'] = max_depth\n",
    "    tmp_params['lambda'] = __lambda\n",
    "\n",
    "    model = xgb.train(tmp_params, X_train, num_boost_round=50)\n",
    "    predicts = model.predict(X_test)\n",
    "\n",
    "    return rmse(y_test, predicts)\n",
    "\n",
    "study = optuna.create_study(direction='min')\n",
    "study.optimize(optimizer, n_trials=500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline = make_pipeline(RobustScaler(), xgb.XGBRegressor(gamma=0.001, learning_rate=0.01, max_depth=2, n_estimators=8000))\n",
    "#pipeline = make_pipeline(RobustScaler(), xgb.XGBRegressor())\n",
    "\n",
    "#params = {'xgbregressor__gamma':[0.001, 0.1, 1, 10, 100],\n",
    "#          'xgbregressor__max_depth':[2,4,6,8,10],\n",
    "#          'xgbregressor__learning_rate':[0.0001, 0.001, 0.01],\n",
    "#          'xgbregressor__n_estimators':[10, 100, 1000]}\n",
    "\n",
    "#if DEBUG:\n",
    "#    params = {'xgbregressor__gamma':[0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "#gd = GridSearchCV(estimator=pipeline, param_grid=params, cv=5, scoring=make_scorer(rmse,greater_is_better=False))\n",
    "pipeline.fit(X_train, y_train)\n",
    "xgboost = pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BEST PARAM(XGBOOST)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#gd.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAKE MODEL AND FIT (LIGHT BGM)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import optuna.integration.lightgbm as lgbo\n",
    "opt_params = { \"objective\":\"regression\", \"metric\":\"rmse\"}\n",
    "reg_train = lgbm.Dataset(X_train, y_train)\n",
    "reg_eval = lgbm.Dataset(X_test, y_test, reference=reg_train)\n",
    "\n",
    "#opt=lgbo.train(opt_params, reg_train, valid_sets = reg_eval, verbose_eval=False, num_boost_round = 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "opt.params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "{'objective': 'regression',\n",
    " 'metric': 'rmse',\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 0.0,\n",
    " 'lambda_l2': 0.0,\n",
    " 'num_leaves': 85,\n",
    " 'feature_fraction': 0.6,\n",
    " 'bagging_fraction': 0.5374366835020357,\n",
    " 'bagging_freq': 3,\n",
    " 'min_child_samples': 5}\n",
    "\"\"\"\n",
    "pipeline = make_pipeline(RobustScaler(), lgbm.LGBMRegressor(objective='regression', num_leaves=85, feature_fraction=0.6, bagging_fraction=0.5374366835020357, bagging_freq=3, min_child_samples=5, max_depth=2))\n",
    "pipeline.fit(X_train, y_train)\n",
    "lightbgm = pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BEST PARAMS(LIGHTBGM)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#gd.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BEST PARAMS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#gd.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STACKING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "xgboost_pred1 = xgboost.predict(X_train)\n",
    "lightbgm_pred1= lightbgm.predict(X_train)\n",
    "\n",
    "print (\"xgboost Model rsme: {:.6f}\".format(rmse(y_train, xgboost_pred1)))\n",
    "print (\"lightbgm pred Model rsme: {:.6f}\".format(rmse(y_train, lightbgm_pred1)))\n",
    "\n",
    "\n",
    "# 結果の検証 \n",
    "xgboost_pred = xgboost.predict(X_test)\n",
    "lightbgm_pred= lightbgm.predict(X_test)\n",
    "print (\"xgboost Model rsme: {:.6f}\".format(rmse(y_test, xgboost_pred)))\n",
    "print (\"lightbgm_pred Model rsme: {:.6f}\".format(rmse(y_test, lightbgm_pred)))\n",
    "\n",
    "final_estimator = MLPRegressor(solver=\"sgd\", random_state=1)\n",
    "st_model = StackingRegressor(estimators=[('xgboost', xgboost),('lightbgm', lightbgm)], final_estimator=final_estimator, cv=5)\n",
    "\n",
    "st_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = st_model.predict(X_train)\n",
    "y_pred = st_model.predict(X_test)\n",
    "print (\"Stacking Model rsme: {:.6f}\".format(rmse(y_train, y_pred_1)))\n",
    "print (\"Stacking Model rsme: {:.6f}\".format(rmse(y_test, y_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PREDICT AND SUBMIT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = df[df_train.shape[0]:].drop(['SalePrice'], axis=1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_ID,\n",
    "    \"SalePrice\": np.expm1(st_model.predict(test))\n",
    "})\n",
    "submission.to_csv(f'{PATH}submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "submission.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}